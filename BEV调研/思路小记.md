### 2022/7/26

##### 自监督 / 无监督的方向：数据， 中间特征

1. 可以 根据时序 特征， 显式提取物体的能量特征（heatmap），类似CenterPoint，但是不知道在现有的 基于Transformer的 融合时序的3D检测中是否已经存在（如BEVDet4D）

2. 基于时序的预测， 如何对齐不同帧特征， 消除 ego 运动误差， 不同 camera的视角数据如何使用， 因为非监督需要的 大量数据只能来自 其他camera的 Image

3. 如果采用对比学习， 那么 如何区分或者是获取 positive sample和negative sample， 评价的指标是什么？——SimSiam可以不需要负样本

4. 针对nuScenes中的3D物体 去除 shandow是否有作用

5. BEV伪点云的方式， 虽然生成了大量的点云数据， 但同时也引入了大量的噪声和计算量， 如何对点云进行稀疏化处理？ 参考：[3D单目(mono 3D)目标检测算法综述 | Johney Zheng](https://johneyzheng.top/posts/3D%E5%8D%95%E7%9B%AE(mono_3D)%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%BB%BC%E8%BF%B0/)
   
   > 非监督方式使用的是LoG(Laplacian of Gaussian)特征用以关键点检测同时采用最近邻算法(k=2)得到点作为前景点.最后得到的前景点被划分到固定的深度区域(depth bins)进行均匀稀疏化.RefinedMPL指出即使只用10%的点,3D物体的检测性能依然没有变差,甚至略由于原始的baseline.同时论文指出pseudo-lidar与真是lidar的性能差距在于其不准确的深度估计.

6. 所以如何提高 Lift 类型的 基于2D图像的 深度估计， Lift是直接使用Conv进行通道变换， 可以采用 某种约束， 现有 单目深度估计有哪些方法？ 
   
   [参考文章](https://zhuanlan.zhihu.com/p/374928597)： <mark>单目深度性能的主要瓶颈是图像分辨率低</mark>

7. 关于深度估计 辅助BEV 进行3D检测， 目前最新的paper为BEVDepth， 在NuScenes上达到NDS指标的SOTA

##### NuScenes数据集

每个scenes长度为20秒，包含了各种各样的情景。在每一个scenes中，有40个关键帧（key frames），也就是每秒钟有2个关键帧，其他的帧为sweeps。

- mini dataset (10 scenes )  中 CAMERA_BACK 的数据量 为 404 关键帧， 1911 其他帧。

- so Full dataset：关键帧—$400 \times 100 \times 6=24w$ 帧， 其他帧约为 $120w $帧

- single camera：$4w + 20w =24 w$

##### 调研汇总

1. 自监督的数据选取，<mark>问题</mark>： Camera View, Timestamp, Scenes。
   
   - 采用 single camera的 时序数据， 需要考虑自车的运动问题；BEVDepth中的Multi frame则是在BEV特征上进行融合。
   
   - 同Scene的camera Back Camera和Front Camera， 通过自监督/无监督提取 通用的表征。
   
   - 不同Scene的复杂问题。

2. 不同 view 的数据是否可以 看成不同的数据集合， 借鉴 ST3D++ 的方式，计算不同数据集的 数据分布（均值和方差），可行的方向：不同Domain的数据投影到同一个 latent space。

3. BEV有效的估计深度， 目前存在LSS的 隐式方式；BEVDepth利用 3D点云做有监督估计的 显式方式。 

4. 自监督方式 可以参考 孪生网络的方式， 对比学习 —— SimSiam， 针对对比学习， 多篇论文提出了  针对 hierarchical 对 不同 layer 的特征 都计算 Contrastive loss

5. 目前相似的论文： PYVA实现单目的BEV 3D检测
