#### 对比学习

1. ContrastiveCrop（对比裁剪）

![2022-07-25 16-08-01 的屏幕截图.png](/home/yihang/Pictures/2022-07-25%2016-08-01%20的屏幕截图.png)

| Title              | Crafting Better Contrastive Views for Siamese Representation Learning                    |
| ------------------ | ---------------------------------------------------------------------------------------- |
| Athour             | Peng, Xiangyu and Wang, Kai and Zhu, Zheng and You, Yang                                 |
| Conference/Journal | CVPR2022                                                                                 |
| Contributes        | 1. 即插即用， 对SimCLR, MoCo等提高0.4%~2%<br/>2. 提出了对比裁剪的思想，同时关于语义信息提出了中心抑制采样<br/>3. 效果在多个方法上泛化性好 |

- Siamese network：孪生网络

- 解决的痛点：目前采用对同一张图片随机裁剪, <font color=red>忽略了语义相关信息</font>； 自监督是采用相同的网络对 pair 输入进行特征提取和 计算对比损失。

- <mark>如何选取这个pair， 以期望能 更快的收敛 或者是 更好的学习收益</mark>

- 达到的目标： 取精华，去糟粕——丢掉相差太远的pair, 也丢掉 差距过小的pair。增大捕捉相同物体的pair 的方差（包含更多可学习的特征）

##### 算法伪代码

![](/home/yihang/.config/marktext/images/2022-07-25-17-23-32-2022-07-25%2017-22-56%20的屏幕截图.png)

采用了β分布：

    用于估计 概率 的概率分布。

$\alpha<1$ 则为U型分布——(x, y) center 更倾向与分布在周围； $\alpha >1 $为凸型分布 

<mark>目前只适用于 single object</mark>

![](/home/yihang/.config/marktext/images/2022-07-25-17-43-58-2022-07-25%2017-43-27%20的屏幕截图.png)

##### 效果图

![](/home/yihang/.config/marktext/images/2022-07-25-16-55-20-2022-07-25%2016-54-51%20的屏幕截图.png)

##### ContrastiveCrop细节

- Semantic-aware Localization： 感知物体的 位置

- Heatmaps: 隐式的表示 物体，  $B=L(1[M>k])$ 获得可能的点簇

- 使用热力图 感知 物体的位置， 对于 高能量 点簇 识别为object 

- 所以就是在 high energy 的周围  进行裁剪？？ 

- Semantic-aware 虽然能 保证pair之间的语义关系， 但是 如何 保证pair 之间的 variance， 文中使用了 Center-suppressed Sampling（中心抑制）， 人为的制造偏差
  
  <mark>引申：</mark>
  
  - 那可以使用高斯分布， CenterPoint的思想实现，  同时用在3D目标检测中吗？
  
  - 但是正如 文中所说， heatmap threshold K影响 点簇的 大小， 对于 object 占比率大的数据可能效果好， 但是对于 samll object 的效果怎么样呢？

##### 实验分析

![](/home/yihang/.config/marktext/images/2022-07-25-17-13-58-2022-07-25%2017-13-49%20的屏幕截图.png)

只使用ContrastiveCrop， 虽然消除了 false positive pair的影响， 但同时也损失了丰富的语义信息（Object和background的区别）。<mark>性能是下降的。</mark>

但是阈值 k变化时， (0.05, 0.20)效果较好， k>0.25时， 效果下降明显， 视野内方差 变小，是的无法学到特征之间的差距。

同时 α <1, positive;  α>1 negative

##### 思考

1. 使用孪生网络训练，无需negative samples， 只需要positive samples. 根据作者提出的思想， 保证训练数据（同语义——同一物体， 高方差）的选取方式， 具有重要意义。

2. 小物体可能 效果 可能并不好， 因为view 较小， 且box 占比小，受到的干扰大， 特征区分不明显。 

3. 怎么 扩展到 多目标问题上面？
