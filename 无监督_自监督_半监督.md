# 无监督、自监督、半监督区别

监督：即是有标签的数据 lable

##### 1. 有监督学习、无监督（半监督学习、非监督学习、自监督学习）

- 监督学习： 所有数据都有标签

- 非监督
  
  - 半监督学习：部分数据有标签
  
  - 无监督学习：所有训练数据都没有标签（K-means聚类等）
  
  - 自监督学习？？[参考链接](https://zhuanlan.zhihu.com/p/108906502)
    
    - 自监督学习是利用辅助任务（pretext）从大规模的的无监督数据中挖掘<font color=red>自身的监督信息</font>，通过这种方法对网络进行训练，从而学习到对<font color=red>下游任务</font>有价值的表征
    
    - 存在的挑战：
      
      大量的无标注数据怎么学习
      
      如何设计学习的方法
      
      如何评测这种表征的有效性（<mark>Pretrain-Fintune</mark>）**自监督学习的能力由下游任务的性能体现**

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9CSmJSdndpYmVTVHNuVjFpYjF5VG9GMHpHT3dsNHJTVnFHbVRtWVRjZlFIRkFneTFUeVlWaWJHNEZ6MGdpYVNUcE5SaWMzdnNRZjZCOTNpYm91Nk9aeHVMclFPdy82NDA?x-oss-process=image/format,png)

##### 2. 自监督学习的方式

1. 基于上下文（Context Based）
   
   主要是数据本身的上下文信息。如NLP中的Word2vec, 以及以后的GPTv1-v3预训练模型
   
   - 图像中可以使用 <mark>空间的相对位置</mark>
   
   - 抠图 <mark>MAE， BERT</mark>
     
     <font color=red>注意：前两者针对下游任务具有一般性</font>
   
   - 同时引申一个问题：自监督的pre context和下游任务的 <mark>紧密程度</mark>—— 针对具体的任务做 <mark>相应的自监督预训练</mark>
   
   ---

2. 基于时序（Temporal Based）
   
   利用<font color=red>时序约束</font> 进行自监督训练，对应的数据类型为 视频， 挖掘 时序特征。
   
   引申—><mark>BEV的时序自监督</mark>
   
   ![](https://pic2.zhimg.com/80/v2-6eed301fec0b96bd1e05da8564888cd1_720w.jpg)
   
   >  
   > 
   > [@Xiaolong Wang](https://www.zhihu.com/people/20416a0babc2f6d9b3932335b1a99a76)
   > 
   >  大佬 ICCV 2015 [18]的基于无监督追踪方法，首先在大量的无标签视频中进行无监督追踪，获取大量的物体追踪框。那么对于一个物体追踪框在不同帧的特征应该是相似的（positive），而对于不同物体的追踪框中的特征应该是不相似的（negative）。
   > 
   > ![](https://pic1.zhimg.com/80/v2-3b6364d41c8a7a3c1780c2c67554c410_720w.jpg)
   
   ---

3. 基于对比学习（Contrastive Based）——MoCo系列
   
   学习<font color=red>两个事物的相似或者不相似编码</font>来构建表征。
   
   <font color=red>注意：对比学习是热点</font>
   
   $score(f(x), f(x^+))>>score(f(x), f(x^-)$
   
   如何分辨 positive 和negtive 样本
   
   > **infoNCE**
   > 
   > ![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cmathcal%7BL%7D_%7BN%7D%3D-%5Cmathbb%7BE%7D_%7BX%7D%5Cleft%5B%5Clog+%5Cfrac%7B%5Cexp+%5Cleft%28f%28x%29%5E%7BT%7D+f%5Cleft%28x%5E%7B%2B%7D%5Cright%29%5Cright%29%7D%7B%5Cexp+%5Cleft%28f%28x%29%5E%7BT%7D+f%5Cleft%28x%5E%7B%2B%7D%5Cright%29%5Cright%29%2B%5Csum_%7Bj%3D1%7D%5E%7BN-1%7D+%5Cexp+%5Cleft%28f%28x%29%5E%7BT%7D+f%5Cleft%28x_%7Bj%7D%5Cright%29%5Cright%29%7D%5Cright%5D+%5Cend%7Bequation%7D)

##### 3.无监督学习

定义：压缩信息，不考虑下流任务，如PCA、Autoencoder、VAE等模型， 目的是<mark>最小化重建误差</mark>（reconstruction error）。
