#### 无监督

#### ST3D

![](/home/yihang/.config/marktext/images/2022-07-26-14-58-04-2022-07-26%2014-57-52%20的屏幕截图.png)

| Title              | ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection |
| ------------------ | ----------------------------------------------------------------------------- |
| Athour             | Jihan Yang1*, Shaoshuai Shi2∗, Zhe Wang3,4, Hongsheng Li2,5, Xiaojuan Qi1     |
| Conference/Journal | CVPR2021                                                                      |

- 基于点云的3D 物体检测， 采用了无监督的 域 适应

- 本文借鉴了memory bank思想

- 主要针对不同场景收集的数据， Waymo数据训练的模型， 在KITTI评测时降低了45%

##### 模型结构

![](/home/yihang/.config/marktext/images/2022-07-27-15-38-09-2022-07-27%2015-37-56%20的屏幕截图.png)

- 为减少 分类损失 对 检测损失的干扰， 只采用和GT ，高IoU的box

- 为标签迭代更新， 采用当前生成的 伪标签集{\{[\hat L_{i}^{t}]_k\}}_{i=1}^{n_t} 和 历史上保存的 伪标签 \{{{[M_i^t]}_{k-1}}\}_{i=1}^{n_t} 的 high overlap IoU中， 有限选择 两个中的一个加入 新的伪标签集中， 生成\{{{[M_i^t]}_{k}}\}_{i=1}^{n_t}

- 之后进行memory voting，针对未匹配的 标签， 更新之后进行投票，类似LRU的思想

- 对 positive和negative模糊的标签进行忽略
  
  ![](/home/yihang/.config/marktext/images/2022-07-27-16-15-45-2022-07-27%2016-15-31%20的屏幕截图.png)

- 以上都是提高pseudo label的质量

##### 思考

- 他使用了MemoryBank的思想， 是否存在MoCo提出的 特征不一致问题， 如果用队列怎么样？ 队列和本文提出的QTMB的区别和优缺点， 使用队列能否满足需求
  
  ![](/home/yihang/.config/marktext/images/2022-07-27-15-46-37-2022-07-27%2015-46-17%20的屏幕截图.png)
  
  消融实验显示：QTMB确实是有效的 

- 但是采用ROS（random object scaling）方式，会不会割裂 object和 背景的区别， 为什么不直接学习 object的 分布 特征

- 同样在BEV空间， 预训练 ROS方式怎么用？？上图显式在$AP_{BEV}$ 通过预训练之后， 效果并不明显， 能进一步发掘/或者提出 相较ROS更好的 预训练方案。

---

#### MoCo: Momentum Contrast

| Title              | Momentum Contrast for Unsupervised Visual Representation Learning |
| ------------------ | ----------------------------------------------------------------- |
| Author             | Kaiming He Haoqi Fan Yuxin Wu Saining Xie Ross Girshick           |
| Conference/Journal | https://arxiv.org/abs/1911.05722                                  |
| Github             | https://github.com/facebookresearch/moco                          |

主要采用了Memory Bank的思想， 存储之前的  采样 特征

##### 问题

- Memory Bank容量大， 导致了采样的特征具有不一致性，因为 训练一段时间后， 更新了参数， 导致 encoder结果在 特征空间 不一致

- MoCo采用队列存储和采样Negetive 样本， 队列中存储多个近期用于训练的batch的特征向量。队列存储的是<mark>图像特征</mark>， 因为队列的<mark>FIFO特性</mark>， 保证 很长时间前的数据 pop，不会被取到。
  
  ![](/home/yihang/.config/marktext/images/2022-07-27-15-32-02-2022-07-27%2015-31-40%20的屏幕截图.png)
  
  ![](/home/yihang/.config/marktext/images/2022-07-27-15-37-32-2022-07-27%2015-37-15%20的屏幕截图.png)

##### 思考

- 自监督也可以使用队列的方式进行存储， 优化方向， 可以是什么？

---

#### DetCo:Unsupervised Contrastive Learning for Object Detection

![](/home/yihang/.config/marktext/images/2022-07-26-16-36-07-2022-07-26%2016-35-50%20的屏幕截图.png)

| Title              | DetCo:Unsupervised Contrastive Learning for Object Detection                                         |
| ------------------ | ---------------------------------------------------------------------------------------------------- |
| Author             | Enze Xie1∗ , Jian Ding3*, Wenhai Wang4, Xiaohang Zhan5, Hang Xu2, Peize Sun1, Zhenguo Li2, Ping Luo1 |
| Conference/Journal | ICCV2021                                                                                             |
| Contributes        |                                                                                                      |

- 基于MoCo 修改， 主要是加入了  patch set，<mark>思考：</mark> 学习了全局和局部之间的关系， So, 如何在BEV空间中 更好的学习 全局和局部的关系， 或者有没有必要——Transformer是否 已经能够 很好地建立 <mark>全局和patch的关系</mark>
- 区别：本文在3D中 用于pose prediction and 3D shape prediction
  ![](/home/yihang/.config/marktext/images/2022-07-26-17-14-39-2022-07-26%2017-14-22%20的屏幕截图.png)

##### 模型结构

   ![](/home/yihang/.config/marktext/images/2022-07-26-16-39-09-2022-07-26%2016-38-57%20的屏幕截图.png)

- 使用了Multi-level Supervision策略， backbone为 ResNet, 4 stage的 feature map都对全局图像$I_q 和I_k$进行损失计算

- 同时充分发掘 全局和局部之间的关系， 具体是将patchs通过特征提取， 然后使用MLP对局部特征进行融合（<font color=red>patch划分问题, 可否使用 swin transformer的方式roll一下</font>）， 同样方法计算全局特征和局部特征融合之后的Loss， 以及patch vs patch的Loss
  
   <mark>引申：</mark>
  
       能不能结合 self supervised 方法 或者 semi-supervised方法——传统方法（聚类）， 获得可靠的 数据类， 然后在对比学习的时候， 使用$I_a$的全局图像和$I_b$的patch进行训练， 是否能得到更底层的特征。

以上思考引申自 simCLR v2.
