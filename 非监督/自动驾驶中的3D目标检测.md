#### 自动驾驶中的3D目标检测

文章：3D Object Detection for Autonomous Driving: A Survey

作者：Rui Qian, Xin Lai, and Xirong Li

编译：点云PCL

来源：arXiv 2021

参考：[自动驾驶中的三维目标检测综述 - 腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/1941743)

![preload](https://ask.qcloudimg.com/http-save/yehe-5926470/968589897d0eaa2275b88bf6bd1f3c2f.png)

##### 数据分类

###### 基于单目

1. 基于模板匹配：倾向于通过全采样和评分3D建议区域作为代表性模板来执行2D/3D匹配

2. 基于几何特性：不需要大量的建议区域来实现高召回率，而是从精确的2D边界框开始，直接从经验观察获得的几何特性粗略估计3D姿势。

3. 基于伪激光雷达：首先进行深度估计，然后再应用于现有的基于点云的方法。
   
   <img src="https://ask.qcloudimg.com/http-save/yehe-5926470/5d92502128dab17a740fbbbcc8f86f9d.png?imageView2/2/w/1620" title="" alt="" data-align="center">
   
   <img src="assets/2022-08-01-17-16-33-2022-08-01%2017-16-20%20的屏幕截图.png" title="" alt="" data-align="center">

###### 基于点云

        由于点云是不规则和无序的，直接卷积它会遭受“形状信息的抛弃和点排序的变化”。基于点云的方法分为基于多视图，体素，点云的方法。

1. 基于多视图：首先将稀疏点云转换为前视图或鸟瞰视图（BEV）表示，这两种表示方法是稠密有规则的，主要是为了利用CNN和标准2D检测方法，该想法直观且简单。

2. 基于体素：常将不规则点云转换为紧凑形状的体积表示，以便通过三维卷积神经网络（3D CNN）有效地提取用于3D检测的点特征。人们相信基于体素的方法在计算上是有效的，但由于离散化过程中的信息丢失，导致细粒度定位精度降低。

3. 基于点：这些方法通常使用利用原始点云，主要有两种方法：PointNet（++）及其变体或图形神经网络（GNN）,通常，它们尽可能保留原始点云的几何图形，然而，与体积网格相比，三维空间中的点检索不利于硬件的高效实现。
   
   <img src="https://ask.qcloudimg.com/http-save/yehe-5926470/91bb49db4d428bffeea1836272f653bd.png?imageView2/2/w/1620" title="" alt="" data-align="center">
   
   <img title="" src="https://ask.qcloudimg.com/http-save/yehe-5926470/862345dd1688cb8ce255a70c34eac32f.png" alt="preload" data-align="center">
   
   <img src="https://ask.qcloudimg.com/http-save/yehe-5926470/845d18ed41d1c35a254936c9527858b9.png?imageView2/2/w/1620" title="" alt="" data-align="center">
   
   <img src="assets/2022-08-01-17-15-54-2022-08-01%2017-15-46%20的屏幕截图.png" title="" alt="" data-align="center">
   
   **具有代表性的3D目标检测的方法：a) VoxelNet , b) SECOND , c) PointRCNN, d) STD , e) PV-RCNN , f) Frustum-PointNets, g) MV3D , h) Pseudo-LiDAR .**
   
   **基于点云3D目标检测方法的发展：1）体素网格，2）点云，3）点云+体素混合。**

###### 基于多模态融合

        目前，用于自动驾驶的三维目标检测在很大程度上依赖于激光雷达提供信息丰富的周围信息。尽管精确，但由于固有的安全风险（如破坏、不利条件和盲点等），过度依赖单个传感器是不够明智的。此外，远距离点云的低分辨率和较差的纹理信息也带来了巨大的挑战。

        不过，相机天生就有深度模糊的问题。

        立体或单目相机比激光雷达便宜几个数量级，具有高帧速率和密集的深度图。

        **当距离较远时，在激光雷达模式中更难区分行人和路标**

<img src="https://ask.qcloudimg.com/http-save/yehe-5926470/ed93c068b4b60e01ec9cda3fdd00033d.png?imageView2/2/w/1620" title="" alt="" data-align="center">

**融合方案**

<img src="https://ask.qcloudimg.com/http-save/yehe-5926470/f8a21c375cd98405450d22857629b9d9.png?imageView2/2/w/1620" title="" alt="" data-align="center">

        不同的融合变体在3D对象检测中始存在的，上述方案可能不适用。例如， pointpainting是一种顺序融合方法，既不适用于早期融合，也不适用于晚期融合。因此，我们定义了两个新的类别：顺序融合和并行融合。

![](https://ask.qcloudimg.com/http-save/yehe-5926470/ec1d3b7d00b8b659c8baf641fc71a0ec.png?imageView2/2/w/1620)

<img src="assets/2022-08-01-17-17-05-2022-08-01%2017-16-54%20的屏幕截图.png" title="" alt="" data-align="center">

**基于多模态融合方法的发展：1）RoI融合，2）像素融合。**

##### 对比实验

<img src="https://ask.qcloudimg.com/http-save/yehe-5926470/7ab59cef4703b6c86a17def43a69e176.png?imageView2/2/w/1620" title="" alt="" data-align="center">

**对于每种最先进的方法，中等难度的汽车类别在2D、3D和BEV目标检测方面的表现。2D对象检测绘制为蓝色三角形，BEV对象检测绘制为绿色圆圈，3D对象检测绘制为红色正方形。两阶段方法绘制为实线，一阶段方法绘制为虚线**

![](https://ask.qcloudimg.com/http-save/yehe-5926470/0bc01e55a24fb850a8c8c98cef6dfceb.png?imageView2/2/w/1620)

![](assets/2022-08-01-17-18-02-2022-08-01%2017-17-52%20的屏幕截图.png)

##### 最新三维目标检测技术的综合比较

![](https://ask.qcloudimg.com/http-save/yehe-5926470/882a5023b222751906812cad41118c62.png?imageView2/2/w/1620)

##### 自动驾驶环境下3D目标检测的公共可用数据集摘要
